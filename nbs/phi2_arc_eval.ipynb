{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, GPT2LMHeadModel, GPT2DoubleHeadsModel\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "from src.settings import MODELS_DIR\n",
    "from src.data.utils.ARC_utils import construct_ARC_prompt\n",
    "from src.data.encoders.ARC_encoder import ARCInputsEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"TheBloke/phi-2-GPTQ\"\n",
    "DATASET = \"ai2_arc\"\n",
    "SUBSET = \"ARC-Challenge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'choices', 'answerKey'],\n",
       "    num_rows: 1172\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(DATASET, SUBSET, split=\"test\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'Mercury_7175875',\n",
       " 'question': 'An astronomer observes that a planet rotates faster after a meteorite impact. Which is the most likely effect of this increase in rotation?',\n",
       " 'choices': {'text': ['Planetary density will decrease.',\n",
       "   'Planetary years will become longer.',\n",
       "   'Planetary days will become shorter.',\n",
       "   'Planetary gravity will become stronger.'],\n",
       "  'label': ['A', 'B', 'C', 'D']},\n",
       " 'answerKey': 'C'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL,\n",
    "    device_map=DEVICE,\n",
    "    trust_remote_code=True,\n",
    "    revision=\"main\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pick one from the given options, A, B, C or D?\n",
      "\n",
      "Question: An astronomer observes that a planet rotates faster after a meteorite impact. Which is the most likely effect of this increase in rotation?\n",
      "Options:\n",
      "\tA. Planetary density will decrease.\n",
      "\tB. Planetary years will become longer.\n",
      "\tC. Planetary days will become shorter.\n",
      "\tD. Planetary gravity will become stronger.\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "prompt = construct_ARC_prompt(\n",
    "    question=dataset[0][\"question\"],\n",
    "    options=dataset[0][\"choices\"][\"text\"],\n",
    "    enum_chars=dataset[0][\"choices\"][\"label\"]\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader_columns = [\n",
    "#     'datasets_idx',\n",
    "#     'input_ids',\n",
    "#     'token_type_ids',\n",
    "#     'attention_mask',\n",
    "#     'start_positions',\n",
    "#     'end_positions',\n",
    "#     'labels'\n",
    "# ]\n",
    "# columns_to_ignore = [c for c in dataset.column_names if c not in loader_columns]\n",
    "# columns_to_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = ARCInputsEncoder(tokenizer=tokenizer, max_seq_length=384)\n",
    "\n",
    "# dataset_transformed = dataset.map(\n",
    "#     encoder,\n",
    "#     batched=True,\n",
    "#     remove_columns=columns_to_ignore,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 32\n",
    "\n",
    "# data_collator = DataCollatorForLanguageModeling(\n",
    "#     tokenizer=tokenizer,\n",
    "#     mlm=False,\n",
    "# )\n",
    "# test_dl = DataLoader(\n",
    "#     dataset_transformed, batch_size=BATCH_SIZE, shuffle=False, collate_fn=data_collator, pin_memory=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(test_dl)).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(test_dl)).input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\\\n",
    "Answer the following question. Pick one from the given options, A, B, C or D?\n",
    "\n",
    "Question: An astronomer observes that a planet rotates faster after a meteorite impact. Which is the most likely effect of this increase in rotation?\n",
    "Options:\n",
    "\tA. Planetary density will decrease.\n",
    "\tB. Planetary years will become longer.\n",
    "\tC. Planetary days will become shorter.\n",
    "\tD. Planetary gravity will become stronger.\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[33706,   262,  1708,  1808,    13, 12346,   530,   422,   262,  1813,\n",
       "          3689,    11,   317,    11,   347,    11,   327,   393,   360,    30,\n",
       "           198,   198, 24361,    25,  1052, 47603, 34526,   326,   257,  5440,\n",
       "          5724,   689,  5443,   706,   257, 19999,   578,  2928,    13,  9022,\n",
       "           318,   262,   749,  1884,  1245,   286,   428,  2620,   287, 13179,\n",
       "            30,   198, 29046,    25,   198,   197,    32,    13, 43800, 12109,\n",
       "           481, 10070,    13,   198,   197,    33,    13, 43800,   812,   481,\n",
       "          1716,  2392,    13,   198,   197,    34,    13, 43800,  1528,   481,\n",
       "          1716, 12238,    13,   198,   197,    35,    13, 43800, 13522,   481,\n",
       "          1716,  7387,    13,   198,   198, 33706,    25,   198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1]])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_prompt = tokenizer(prompt, return_tensors=\"pt\")\n",
    "encoded_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[33706,   262,  1708,  1808,    13, 12346,   530,   422,   262,  1813,\n",
       "          3689,    11,   317,    11,   347,    11,   327,   393,   360,    30,\n",
       "           198,   198, 24361,    25,  1052, 47603, 34526,   326,   257,  5440,\n",
       "          5724,   689,  5443,   706,   257, 19999,   578,  2928,    13,  9022,\n",
       "           318,   262,   749,  1884,  1245,   286,   428,  2620,   287, 13179,\n",
       "            30,   198, 29046,    25,   198,   197,    32,    13, 43800, 12109,\n",
       "           481, 10070,    13,   198,   197,    33,    13, 43800,   812,   481,\n",
       "          1716,  2392,    13,   198,   197,    34,    13, 43800,  1528,   481,\n",
       "          1716, 12238,    13,   198,   197,    35,    13, 43800, 13522,   481,\n",
       "          1716,  7387,    13,   198,   198, 33706,    25,   198,   198,    33,\n",
       "            13, 43800,   812,   481,  1716,  2392,    13,   198,   198,  3109,\n",
       "         11578,   341,    25,   198,   198, 19722,   317,   318,   407,   257,\n",
       "         12219,  7664,   355,   262, 12109,   286,   257,  5440,   857,   407,\n",
       "           423,   257,  1277,  2776,   351,   663, 13179,    13, 16018,   327,\n",
       "           318,   257,  1277,  6697,   286,   262,  1813,  2643,   355,   340,\n",
       "         40081,   262,  3721,   286,   257,  5440,   338, 13179,    13, 16018,\n",
       "           360,   318,   407,  3264,  3519,   284,   262,  1813,  2643,    13,\n",
       "         16018,   347,   318,   262,   691, 12219,  3280,   355,   262, 13179,\n",
       "           286,   257,  5440, 10975,   262,  4129,   286,   663,  1110,    13,\n",
       "          1649,   257,  5440,  5724,   689,  5443,    11,   340,  2753,  1342,\n",
       "           640,   284,  1844,   530, 13179,    11,  1642,   262,  1528, 12238,\n",
       "            13,  4619,   262,  5440,   338,   614,   318,   257,  3294,   286,\n",
       "           262,  1271,   286,  1528,    11,   257, 12238,  1110,   481,  1255,\n",
       "           287,  2392,   812,    13,   198,   198,  7155,    12,   929, 32900,\n",
       "           352,    25,   198,   198, 24361,    25,   383,  5440,   287,   262,\n",
       "          2180,  5517,   468,   257, 16874,   286,   642,    11,   830, 10571,\n",
       "            13, 27131,   378,   262,  5440,   338, 32558, 15432,   287,  2511,\n",
       "          1547,   583,  1218,   878,   290,   706,   262, 19999,   578,  2928,\n",
       "            13,   198,   198, 33706,    25,   198,   198, 13450,   934, 15432,\n",
       "           878,  2928,    25,   198,   198, 13450,   934, 15432,   796,   357,\n",
       "            17, 46582,  2124,   642,    11,   830, 10571,     8,  1220,   357,\n",
       "          1731,  2250,  2124,  3126,  2431,  2124,  3126,  4201,     8,   198,\n",
       "            28,   657,    13,   486,  5332,  2511,  1547,   583,  1218,   198,\n",
       "           198, 13450,   934, 15432,   706,  2928,    25,   198,   198, 13450,\n",
       "           934, 15432,   796,   357,    17, 46582,  2124,   642,    11,   830,\n",
       "         10571,     8,  1220,   357,  1731,  2250,  2124,  3126,  2431,  2124,\n",
       "          3126,  4201,     8,   198,    28,   657,    13,   486,  2425,  2511,\n",
       "          1547,   583,  1218,   198,   198,  7155,    12,   929, 32900,   362,\n",
       "            25,   198,   198, 24361,    25,  1002,   262,  5440,   338,  5724,\n",
       "           864, 15432,  5732,   416,   362,     4,   706,   262, 19999,   578,\n",
       "          2928,    11,   703,   881,   640,   481,   262,  5440,  1011,   284,\n",
       "          1844,   530, 13179,    30,   198,   198, 33706,    25,   198,   198,\n",
       "           464,  5440,   338,   649, 32558, 15432,   796,   657,    13,   486,\n",
       "          2425,  1343,   657,    13,   486,  2425,  2124,   362,     4,   796,\n",
       "           657,    13,   486,  6659,  2511,  1547,   583,  1218,    13,   198,\n",
       "           198,  7575,  2077,   284,  1844,   530, 13179,   796,   357,    17,\n",
       "         46582,  2124,   642,    11,   830, 10571,     8,  1220,   657,    13,\n",
       "           486,  6659,  2511,  1547,   583,  1218,   198,    28,   767,    11,\n",
       "            23,  4304,    13,    17,  4201,   393,  6702,   642,  2250,   290,\n",
       "          1315,  2431,    13,   198,   198,  7155,    12,   929, 32900,   513,\n",
       "            25,   198,   198, 24361,    25,   383,  5440,   338, 32362,  2278,\n",
       "           878,   262, 19999,   578,  2928,   373, 21268,    13,  1495,  1528,\n",
       "            13, 27131,   378,   663,   649, 32362,  2278,   706,   262,  2928,\n",
       "            13,   198,   198, 33706,    25,   198,   198,   464,  5440,   338,\n",
       "           649, 32362,  2278,   796, 21268,    13,  1495,  1528,  2124,   357,\n",
       "            17, 46582,  2124,   642,    11,   830, 10571,     8,  1220,   357,\n",
       "          1731,  2250,  2124,  3126,  2431,  2124,  3126,  4201,     8,   198,\n",
       "            28, 21268,    13,  1495,  1528,  2124,   357,    17, 46582,  2124,\n",
       "           642,    11,   830, 10571,     8,  1220,   357,  1731,  2250,  2124,\n",
       "          3126,  2431,  2124,  3126,  4201,     8,   198,    28, 21268,    13,\n",
       "          1495,  1528,  2124,   767,    13,    23,  4304,  4201,   198,    28]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.generate(\n",
    "    inputs=encoded_prompt.input_ids.to(DEVICE),\n",
    "    temperature=0.7,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following question. Pick one from the given options, A, B, C or D?\n",
      "\n",
      "Question: An astronomer observes that a planet rotates faster after a meteorite impact. Which is the most likely effect of this increase in rotation?\n",
      "Options:\n",
      "\tA. Planetary density will decrease.\n",
      "\tB. Planetary years will become longer.\n",
      "\tC. Planetary days will become shorter.\n",
      "\tD. Planetary gravity will become stronger.\n",
      "\n",
      "Answer:\n",
      "\n",
      "B. Planetary years will become longer.\n",
      "\n",
      "Explanation:\n",
      "\n",
      "Option A is not a logical conclusion as the density of a planet does not have a direct relationship with its rotation. Option C is a direct opposite of the given statement as it contradicts the concept of a planet's rotation. Option D is not directly related to the given statement. Option B is the only logical answer as the rotation of a planet affects the length of its day. When a planet rotates faster, it takes less time to complete one rotation, making the days shorter. Since the planet's year is a multiple of the number of days, a shorter day will result in longer years.\n",
      "\n",
      "Follow-up Exercise 1:\n",
      "\n",
      "Question: The planet in the previous exercise has a radius of 5,000 km. Calculate the planet's angular velocity in radians per second before and after the meteorite impact.\n",
      "\n",
      "Answer:\n",
      "\n",
      "Angular velocity before impact:\n",
      "\n",
      "Angular velocity = (2π x 5,000 km) / (24 hours x 60 minutes x 60 seconds)\n",
      "= 0.0185 radians per second\n",
      "\n",
      "Angular velocity after impact:\n",
      "\n",
      "Angular velocity = (2π x 5,000 km) / (24 hours x 60 minutes x 60 seconds)\n",
      "= 0.0175 radians per second\n",
      "\n",
      "Follow-up Exercise 2:\n",
      "\n",
      "Question: If the planet's rotational velocity increases by 2% after the meteorite impact, how much time will the planet take to complete one rotation?\n",
      "\n",
      "Answer:\n",
      "\n",
      "The planet's new angular velocity = 0.0175 + 0.0175 x 2% = 0.0181 radians per second.\n",
      "\n",
      "Time taken to complete one rotation = (2π x 5,000 km) / 0.0181 radians per second\n",
      "= 7,876.2 seconds or approximately 5 hours and 15 minutes.\n",
      "\n",
      "Follow-up Exercise 3:\n",
      "\n",
      "Question: The planet's orbital period before the meteorite impact was 365.25 days. Calculate its new orbital period after the impact.\n",
      "\n",
      "Answer:\n",
      "\n",
      "The planet's new orbital period = 365.25 days x (2π x 5,000 km) / (24 hours x 60 minutes x 60 seconds)\n",
      "= 365.25 days x (2π x 5,000 km) / (24 hours x 60 minutes x 60 seconds)\n",
      "= 365.25 days x 7.876 seconds\n",
      "=\n"
     ]
    }
   ],
   "source": [
    "decoded_pred = tokenizer.batch_decode(pred, skip_special_tokens=True)\n",
    "print(decoded_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_dl):\n",
    "#         batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "#         # predictions = model.generate(\n",
    "#         #     input_ids=batch[\"input_ids\"],\n",
    "#         #     max_length=encoder.max_seq_length,\n",
    "#         #     attention_mask=batch[\"attention_mask\"],\n",
    "#         # )\n",
    "#         predictions = model.generate(\n",
    "#             inputs=batch[\"input_ids\"],\n",
    "#             temperature=0.7,\n",
    "#             do_sample=True,\n",
    "#             top_p=0.95,\n",
    "#             top_k=40,\n",
    "#             max_new_tokens=512\n",
    "#         )\n",
    "#         decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "#         for i, pred in enumerate(decoded_predictions):\n",
    "#             if i == 4:\n",
    "#                 break\n",
    "#             print(\"-\" * 80, \"\\n\", pred)\n",
    "\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
